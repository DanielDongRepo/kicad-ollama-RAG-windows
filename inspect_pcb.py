import json
import os
import chromadb
from langchain_community.llms import Ollama
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import OllamaEmbeddings
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate




def load_pcb_data(json_file="pcb_data.json"):
    if not os.path.exists(json_file):
        raise FileNotFoundError(f"PCB æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {os.path.abspath(json_file)}")

    with open(json_file, "r", encoding="utf-8") as f:
        return json.load(f)


def analyze_with_rag(pcb_data, model_name="qwen3:4b"):
    persist_dir = "./chroma_db"
    collection_name = "kicad_docs"

    if not os.path.exists(persist_dir):
        raise FileNotFoundError(f"å‘é‡åº“ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ build_vector_db.py: {os.path.abspath(persist_dir)}")

    try:
        # === å…³é”®ä¿®æ”¹ï¼šä½¿ç”¨ PersistentClient åŠ è½½å‘é‡åº“ ===
        client = chromadb.PersistentClient(path=persist_dir)
        embedding_model = OllamaEmbeddings(model="nomic-embed-text")

        vectorstore = Chroma(
            client=client,
            collection_name=collection_name,
            embedding_function=embedding_model
        )

        # æµ‹è¯•æ˜¯å¦èƒ½æ£€ç´¢
        test_results = vectorstore.similarity_search("test", k=1)
        print(f"âœ… å‘é‡åº“åŠ è½½æˆåŠŸï¼Œæµ‹è¯•æ£€ç´¢è¿”å› {len(test_results)} ä¸ªç»“æœ")

    except Exception as e:
        print(f"âŒ å‘é‡åº“åŠ è½½å¤±è´¥: {e}")
        print("ğŸ’¡ è¯·ç¡®ä¿:")
        print("   1. å·²ç”¨æ–°ç‰ˆ build_vector_db.py æˆåŠŸæ„å»ºå‘é‡åº“")
        print("   2. Ollama æ­£åœ¨è¿è¡Œï¼ˆollama serveï¼‰")
        print("   3. æ¨¡å‹å·²ä¸‹è½½: ollama pull nomic-embed-text å’Œ ollama pull qwen3:4b")
        raise e

    # åˆå§‹åŒ– LLM
    llm = Ollama(model=model_name, temperature=0.1)

    # æ„é€ è®¾è®¡æ‘˜è¦
    min_track = min([t["width_mm"] for t in pcb_data["tracks"]]) if pcb_data["tracks"] else 0
    design_summary = f"""
å½“å‰ PCB è®¾è®¡æ‘˜è¦ï¼š
- æœ€å°èµ°çº¿å®½åº¦: {min_track:.3f} mm
- å…ƒä»¶æ•°é‡: {len(pcb_data['components'])}
- èµ°çº¿æ•°é‡: {len(pcb_data['tracks'])}

è¯·æ ¹æ®å…¬å¸è§„èŒƒæ£€æŸ¥ï¼š
1. èµ°çº¿å®½åº¦æ˜¯å¦åˆè§„ï¼Ÿ
2. æ˜¯å¦å­˜åœ¨å»è€¦ç”µå®¹ç¼ºå¤±é£é™©ï¼Ÿ
3. å…¶ä»–æ½œåœ¨é—®é¢˜ï¼Ÿ

è¯·é€æ¡åˆ—å‡ºï¼Œå¹¶å¼•ç”¨è§„èŒƒæ¡æ¬¾ã€‚
"""

    # å®šä¹‰ Prompt
    prompt_template = """
ä½ æ˜¯ä¸€ä½èµ„æ·±ç¡¬ä»¶å·¥ç¨‹å¸ˆï¼Œè¯·ä¸¥æ ¼åŸºäºä»¥ä¸‹è§„èŒƒå›ç­”ã€‚

è§„èŒƒå†…å®¹ï¼š
{context}

è®¾è®¡æ•°æ®ï¼š
{question}

è¦æ±‚ï¼š
- ä»…åŸºäºä¸Šè¿°å†…å®¹å›ç­”
- è‹¥ä¸ç¡®å®šï¼Œå›ç­”â€œæ— æ³•åˆ¤æ–­â€
- ç”¨ä¸­æ–‡æ¸…æ™°åˆ—å‡ºé—®é¢˜
"""
    PROMPT = PromptTemplate(template=prompt_template, input_variables=["context", "question"])

    # æ„å»º RAG é“¾
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=vectorstore.as_retriever(search_kwargs={"k": 4}),
        chain_type="stuff",
        chain_type_kwargs={"prompt": PROMPT}
    )

    print("ğŸ” æ­£åœ¨åˆ†æ...\n")
    response = qa_chain.invoke({"query": design_summary})
    return response["result"]


if __name__ == "__main__":
    try:
        print("ğŸ“‹ å¼€å§‹ PCB æ™ºèƒ½åˆ†æ...")
        pcb_data = load_pcb_data()
        print(f"âœ… åŠ è½½ PCB æ•°æ®: {len(pcb_data['tracks'])} æ¡èµ°çº¿, {len(pcb_data['components'])} ä¸ªå…ƒä»¶")

        report = analyze_with_rag(pcb_data, model_name="qwen3:4b")
        print("\n" + "=" * 50)
        print("ğŸ“‹ PCB æ™ºèƒ½æ£€æŸ¥æŠ¥å‘Š:")
        print("=" * 50)
        print(report)

        # ä¿å­˜æŠ¥å‘Š
        with open("pcb_analysis_report.txt", "w", encoding="utf-8") as f:
            f.write(report)
        print(f"\nâœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {os.path.abspath('pcb_analysis_report.txt')}")

    except Exception as e:
        error_msg = f"âŒ é”™è¯¯: {e}"
        print(error_msg)
        with open("error.log", "w", encoding="utf-8") as f:
            f.write(error_msg)
        raise